import json
import sys
import re
from pathlib import Path

# --- é…ç½® ---
# SOURCE_DIR = Path(".") 
SOURCE_DIR = Path(sys.argv[1]) if len(sys.argv) > 1 else Path(".")
# ä¸ºè¿™ç§æ ¼å¼ä½¿ç”¨ä¸€ä¸ªä¸“é—¨çš„è¾“å‡ºæ–‡ä»¶å¤¹
OUTPUT_DIR = Path("chatgpt_markdown_output")

def sanitize_filename(filename: str) -> str:
    """å¢å¼ºç‰ˆæ–‡ä»¶åæ¸…ç†å‡½æ•°ã€‚"""
    if not filename or not filename.strip():
        return "æœªå‘½åå¯¹è¯"
    filename = filename.replace('\n', ' ').replace('\r', ' ')
    filename = re.sub(r'[\\/*?:"<>|]', "", filename)
    filename = re.sub(r'\s+', '_', filename)
    filename = filename[:100]
    filename = filename.strip('_')
    return filename or "ç‰¹æ®Šå­—ç¬¦å¯¹è¯"

def get_unique_filepath(output_dir: Path, filename: str) -> Path:
    """ç¡®ä¿ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„æ˜¯å”¯ä¸€çš„ï¼Œé˜²æ­¢è¦†ç›–ã€‚"""
    base_path = output_dir / (filename + ".md")
    if not base_path.exists():
        return base_path
    counter = 1
    while True:
        new_path = output_dir / f"{filename}({counter}).md"
        if not new_path.exists():
            return new_path
        counter += 1

def convert_tree_based_chat_to_markdown(conversation_data: dict, output_md_path: Path) -> bool:
    """
    ã€æ‚¨çš„åŸå§‹æ ¸å¿ƒé€»è¾‘ã€‘è§£æåŸºäº'mapping'çš„å•ä¸ªå¯¹è¯æ ‘çŠ¶ç»“æ„ã€‚
    """
    mapping = conversation_data.get('mapping')
    if not mapping:
        return False

    # æŸ¥æ‰¾æ ¹èŠ‚ç‚¹ (æ²¡æœ‰çˆ¶èŠ‚ç‚¹çš„èŠ‚ç‚¹)
    root_node_id = next((key for key in mapping if mapping[key].get('parent') is None), None)
    if not root_node_id:
        return False
    
    root_node = mapping.get(root_node_id, {})

    # å¯»æ‰¾å®é™…å¯¹è¯çš„èµ·å§‹èŠ‚ç‚¹ID
    current_node_id = None
    if 'client-created-root' in mapping and mapping['client-created-root'].get('children'):
         current_node_id = mapping['client-created-root']['children'][0]
    elif root_node.get('children'):
         current_node_id = root_node['children'][0]
    else:
         return False # æ²¡æœ‰å¯¹è¯å†…å®¹

    has_content = False
    with open(output_md_path, 'w', encoding='utf-8') as md_file:
        # æ²¿ç€å¯¹è¯æ ‘çš„å­èŠ‚ç‚¹é“¾æ¡éå†
        while current_node_id:
            node = mapping.get(current_node_id)
            if not node or not node.get('message'):
                break

            message = node['message']
            role = message.get('author', {}).get('role')
            content_parts = message.get('content', {}).get('parts', [])
            full_content = "".join(part for part in content_parts if isinstance(part, str)).strip()

            if role == 'user' and full_content:
                md_file.write(f"# ç”¨æˆ·: {full_content}\n\n---\n\n")
                has_content = True
            elif role == 'assistant' and full_content:
                md_file.write(f"## å›ç­”\n\n{full_content}\n\n")
                has_content = True
            
            children = node.get('children', [])
            current_node_id = children[0] if children else None
            
    return has_content

def pre_check_files(json_files: list):
    """
    ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿåˆ†ææ‰€æœ‰JSONæ–‡ä»¶ï¼ŒæŠ¥å‘Šæ¯ä¸ªæ–‡ä»¶çš„å¯¹è¯æ•°å’Œæ€»æ•°ã€‚
    """
    print("--- é˜¶æ®µ 1: é¢„è®¡ç®—åˆ†æ ---")
    file_counts = []
    total_conversations = 0
    
    for filepath in json_files:
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            # è¿™ç§æ ¼å¼çš„JSONï¼Œé¡¶å±‚æœ¬èº«å°±æ˜¯ä¸€ä¸ªå¯¹è¯åˆ—è¡¨
            if isinstance(data, list):
                count = len(data)
                file_counts.append((filepath.name, count))
                total_conversations += count
            else:
                file_counts.append((filepath.name, 0, "ç»“æ„ä¸ç¬¦ (é¡¶å±‚ä¸æ˜¯åˆ—è¡¨)"))
        except (json.JSONDecodeError, IOError):
            file_counts.append((filepath.name, 0, "æ— æ³•è§£æ"))
    
    print("åˆ†æç»“æœ:")
    for name, count, *error in file_counts:
        status = f"-> åŒ…å« {count} æ®µå¯¹è¯" if not error else f"-> é”™è¯¯: {error[0]}"
        print(f"  - æ–‡ä»¶: {name.ljust(40)} {status}")
        
    print("-" * 30)
    print(f"åˆ†æå®Œæˆï¼æ€»å…±å°†åœ¨ {len(json_files)} ä¸ªæ–‡ä»¶ä¸­å¤„ç† {total_conversations} æ®µå¯¹è¯ã€‚")
    print("="*40)

def process_tree_based_file(input_path: Path):
    """è¯»å–æŒ‡å®šçš„æ ‘çŠ¶æ ¼å¼JSONæ–‡ä»¶ï¼Œå¹¶ä¸ºæ¯ä¸ªå¯¹è¯ç”ŸæˆMarkdownã€‚"""
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            # å¯¹äºè¿™ç§æ ¼å¼ï¼Œæ•´ä¸ªæ–‡ä»¶å°±æ˜¯ä¸€ä¸ªå¯¹è¯åˆ—è¡¨
            conversations = json.load(f)
    except Exception:
        return 0, 0, 1

    if not isinstance(conversations, list):
        # é”™è¯¯å·²åœ¨é¢„è®¡ç®—é˜¶æ®µæŠ¥å‘Šï¼Œè¿™é‡Œä»…ä½œé˜²å¾¡
        return 0, 0, 1

    success_count, skipped_count = 0, 0
    num_total = len(conversations)
    print(f"\nå¤„ç†ä¸­: {input_path.name} (å…± {num_total} æ®µå¯¹è¯)")

    for i, conv in enumerate(conversations):
        # ä½¿ç”¨åŸå§‹è„šæœ¬ä¸­çš„æ ‡é¢˜ç”Ÿæˆé€»è¾‘
        title = conv.get('title', f"å¯¹è¯_{conv.get('conversation_id', i + 1)}")
        safe_filename = sanitize_filename(title)
        md_path = get_unique_filepath(OUTPUT_DIR, safe_filename)
        
        if convert_tree_based_chat_to_markdown(conv, md_path):
            print(f"  ({i+1}/{num_total}) -> æˆåŠŸ: {md_path.name}")
            success_count += 1
        else:
            print(f"  ({i+1}/{num_total}) -> è­¦å‘Š: å¯¹è¯ '{title}' ä¸ºç©ºæˆ–ç»“æ„ä¸å®Œæ•´ï¼Œå·²è·³è¿‡ã€‚")
            skipped_count += 1
    return success_count, skipped_count, 0

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°ï¼ŒåŒ…å«é¢„è®¡ç®—å’Œè½¬æ¢ä¸¤ä¸ªé˜¶æ®µã€‚"""
    print(f"--- ChatGPT/æ ‘çŠ¶æ ¼å¼å¯¹è¯è®°å½•è½¬æ¢å™¨ (æ ‡å‡†åŒ–ç‰ˆ) ---")
    
    try:
        OUTPUT_DIR.mkdir(exist_ok=True)
    except PermissionError:
        print(f"ä¸¥é‡é”™è¯¯: æ— æ³•åˆ›å»ºæ–‡ä»¶å¤¹ '{OUTPUT_DIR}'ã€‚è¯·æ£€æŸ¥æƒé™ã€‚")
        sys.exit(1)

    json_files = sorted(list(SOURCE_DIR.glob('*.json')))
    if not json_files:
        print("ä¿¡æ¯: å½“å‰æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .json æ–‡ä»¶ã€‚")
        sys.exit(0)

    pre_check_files(json_files)

    print("\n--- é˜¶æ®µ 2: å¼€å§‹æ­£å¼è½¬æ¢ ---")
    total_success, total_skipped, total_file_errors = 0, 0, 0
    for filepath in json_files:
        success, skipped, file_error = process_tree_based_file(filepath)
        total_success += success
        total_skipped += skipped
        total_file_errors += file_error
            
    print("\n" + "="*40)
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼ ğŸ‰")
    print(f"æ€»è®¡æˆåŠŸç”Ÿæˆ: {total_success} ä¸ªMarkdownæ–‡æ¡£")
    if total_skipped > 0:
        print(f"æ€»è®¡è·³è¿‡(ç©ºæˆ–æŸåçš„å¯¹è¯): {total_skipped} ä¸ª")
    if total_file_errors > 0:
        print(f"å¤„ç†å¤±è´¥çš„æ–‡ä»¶æ•°: {total_file_errors} ä¸ª (è¯¦ç»†é”™è¯¯è§ä¸Šæ–¹åˆ†æ)")
    print(f"æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜è‡³ '{OUTPUT_DIR}' æ–‡ä»¶å¤¹ã€‚")

if __name__ == "__main__":
    main()